"""
GPT ë¶„ì„ ì„œë¹„ìŠ¤

GPT API í˜¸ì¶œì„ í†µí•© ê´€ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤ ë ˆì´ì–´
- ë‹¨ì¼ OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
- ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
- ìºì‹± ì§€ì› (í–¥í›„ í™•ì¥)
"""
import os
import logging
import traceback
from typing import Optional, List, Dict, Any, Tuple
from openai import APIError, RateLimitError, APIConnectionError, APITimeoutError, AuthenticationError
import time

from common.openai_client import get_openai_client, is_openai_available

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)


class GPTService:
    """GPT ë¶„ì„ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self._client = None
    
    @property
    def client(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ (ì§€ì—° ë¡œë”©)"""
        if self._client is None:
            self._client = get_openai_client()
        return self._client
    
    def generate_cluster_summary(
        self, 
        cluster_id: str, 
        top_keywords: List[str], 
        size: int, 
        category: str
    ) -> Optional[str]:
        """
        í´ëŸ¬ìŠ¤í„° ìš”ì•½ ìƒì„±
        
        Args:
            cluster_id: í´ëŸ¬ìŠ¤í„° ID
            top_keywords: ìƒìœ„ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            size: í´ëŸ¬ìŠ¤í„° í¬ê¸°
            category: ì¹´í…Œê³ ë¦¬
            
        Returns:
            ìš”ì•½ í…ìŠ¤íŠ¸ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        if not is_openai_available():
            return None
        
        keywords_text = ", ".join(top_keywords[:20]) if top_keywords else "No keywords"
        
        prompt = f"""ë‹¤ìŒì€ í´ëŸ¬ìŠ¤í„° '{cluster_id}' ({category})ì˜ ì •ë³´ì…ë‹ˆë‹¤.

í´ëŸ¬ìŠ¤í„° ì •ë³´:
- í¬ê¸°: {size}ê°œ í¬ìŠ¤íŠ¸
- ì£¼ìš” í‚¤ì›Œë“œ: {keywords_text}

ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ í´ëŸ¬ìŠ¤í„°ê°€ ë‹¤ë£¨ëŠ” ì£¼ì œì™€ ì£¼ìš” ê´€ì‹¬ì‚¬ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”.

í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš” (2-3ë¬¸ì¥)."""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a content analyst summarizing topic clusters."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=200
            )
            return response.choices[0].message.content.strip()
        except (APIError, RateLimitError, APIConnectionError, APITimeoutError) as e:
            print(f"Error calling GPT API for cluster summary: {e}")
            return None
        except Exception as e:
            print(f"Unexpected error in generate_cluster_summary: {e}")
            return None
    
    def generate_master_topics(
        self,
        topic_category: str,
        reddit_clusters: List[Dict[str, Any]],
        serp_questions: List[str]
    ) -> Optional[str]:
        """
        ë§ˆìŠ¤í„° í† í”½ ìƒì„±
        
        Args:
            topic_category: í† í”½ ì¹´í…Œê³ ë¦¬
            reddit_clusters: Reddit í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            serp_questions: SERP ì§ˆë¬¸í˜• í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ë§ˆìŠ¤í„° í† í”½ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        if not is_openai_available():
            return None
        
        # Reddit í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ í¬ë§·íŒ…
        reddit_data = []
        for cluster in reddit_clusters:
            cluster_info = f"""
- Cluster ID: {cluster.get('cluster_id', 'N/A')}
- Sub Cluster ID: {cluster.get('sub_cluster_id', 'N/A')}
- Cluster Size: {cluster.get('cluster_size', 0)}
- Top Keywords: {', '.join(cluster.get('top_keywords', [])[:10])}
- Summary: {cluster.get('summary', 'N/A')}
"""
            # ëŒ€í‘œ í¬ìŠ¤íŠ¸ ìš”ì•½ ì¶”ê°€
            rep_posts = cluster.get('representative_posts', [])
            if rep_posts:
                cluster_info += "- ëŒ€í‘œ í¬ìŠ¤íŠ¸:\n"
                for post in rep_posts[:3]:
                    title = post.get('title', 'N/A')
                    cluster_info += f"  * {title}\n"
            reddit_data.append(cluster_info)
        
        reddit_text = "\n".join(reddit_data) if reddit_data else "Reddit í´ëŸ¬ìŠ¤í„°ë§ ë°ì´í„° ì—†ìŒ"
        
        # SERP ì§ˆë¬¸í˜• í‚¤ì›Œë“œ í¬ë§·íŒ…
        serp_text = "\n".join([f"- {q}" for q in serp_questions[:100]]) if serp_questions else "SERP ì§ˆë¬¸í˜• í‚¤ì›Œë“œ ì—†ìŒ"
        
        # GPT í”„ë¡¬í”„íŠ¸
        prompt = f"""ë„ˆëŠ” ë°ì´í„° ê¸°ë°˜ ì½˜í…ì¸  ì „ëµê°€ë‹¤.
ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§„ Reddit í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ì™€ SERP ì§ˆë¬¸í˜• í‚¤ì›Œë“œëŠ”
"ì§€ê¸ˆ ì‚¬ëŒë“¤ì´ ì‹¤ì œë¡œ ê²ªëŠ” ë¬¸ì œ"ì™€
"ì§€ê¸ˆ ê²€ìƒ‰ì—ì„œ ë“œëŸ¬ë‚˜ëŠ” ì •ë³´ ìˆ˜ìš”"ë¥¼ ê°ê° ì˜ë¯¸í•œë‹¤.

ë„ˆì˜ ì„ë¬´ëŠ”,
ì´ ë‘ ì‹ í˜¸ë¥¼ ê²°í•©í•´
LGì „ì ë¸”ë¡œê·¸/ì†Œì…œì—ì„œ ì§€ê¸ˆ ì‹œì ì— ë‹¤ë¤„ì•¼ í• 
'ë§ˆìŠ¤í„° í† í”½(Master Topic)'ì„ ë„ì¶œí•˜ëŠ” ê²ƒì´ë‹¤.

ì¤‘ìš”í•œ ê¸°ì¤€:
- Reddit ë°ì´í„°ëŠ” "ì™œ ì‚¬ëŒë“¤ì´ ì´ ì£¼ì œì— ê´€ì‹¬ì„ ê°€ì§€ëŠ”ì§€"
- SERP ì§ˆë¬¸ì€ "ì‚¬ëŒë“¤ì´ ì‹¤ì œë¡œ ì–´ë–¤ ì§ˆë¬¸ì„ ë˜ì§€ê³  ìˆëŠ”ì§€"
ë¥¼ ë³´ì—¬ì¤€ë‹¤.
ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©í•´ì„œëŠ” ì•ˆ ëœë‹¤.

ê° topic_categoryì— ëŒ€í•´:
- ë§ˆìŠ¤í„° í† í”½ 5ê°œë§Œ ìƒì„±í•˜ë¼.
- ê° ë§ˆìŠ¤í„° í† í”½ì—ëŠ” ë°˜ë“œì‹œ "Why now"ê°€ í¬í•¨ë˜ì–´ì•¼ í•œë‹¤.
- Why nowëŠ” ë‹¤ìŒ ë‘ ìš”ì†Œë¥¼ ë°˜ë“œì‹œ ì—°ê²°í•´ ì„¤ëª…í•´ì•¼ í•œë‹¤:
  1) Reddit í´ëŸ¬ìŠ¤í„°ì—ì„œ ê´€ì°°ëœ ì‚¬ìš©ì ë§¥ë½/ë¶ˆí¸/ìš•êµ¬
  2) SERP ì§ˆë¬¸í˜• í‚¤ì›Œë“œì—ì„œ ë‚˜íƒ€ë‚œ ê²€ìƒ‰ ì˜ë„ íŒ¨í„´

ì¶œë ¥ ì‹œ ì£¼ì˜ì‚¬í•­:
- "íŠ¸ë Œë“œë‹¤", "ì¤‘ìš”í•˜ë‹¤" ê°™ì€ ì¶”ìƒì  í‘œí˜„ ê¸ˆì§€
- ê³„ì ˆì„±, í–‰ë™ ë³€í™”, ë°˜ë³µ ì§ˆë¬¸, ë¬¸ì œ ì „í™˜ ê°™ì€
  'ì§€ê¸ˆ ì‹œì ì„±'ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•´ì•¼ í•œë‹¤.
- ë§ˆì¼€íŒ… ë¬¸êµ¬ì²˜ëŸ¼ ì“°ì§€ ë§ê³ ,
  ì „ëµ ë¬¸ì„œì— ë°”ë¡œ ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•˜ë¼.

[ì…ë ¥ ë°ì´í„°]

Topic Category: {topic_category}

[Reddit í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼]
{reddit_text}

[SERP ì§ˆë¬¸í˜• í‚¤ì›Œë“œ]
{serp_text}

[ì¶œë ¥ í¬ë§· - ë°˜ë“œì‹œ ì´ í˜•ì‹ ìœ ì§€]

## {topic_category}

1) **{{ë§ˆìŠ¤í„° í† í”½ ì œëª©}}**
- **Why now:** {{2~3ë¬¸ì¥ìœ¼ë¡œ, Reddit ì‹ í˜¸ + SERP ì§ˆë¬¸ì„ ì—°ê²°í•´ ì„¤ëª…}}

2) **{{ë§ˆìŠ¤í„° í† í”½ ì œëª©}}**
- **Why now:** {{â€¦}}

3) **{{ë§ˆìŠ¤í„° í† í”½ ì œëª©}}**
- **Why now:** {{â€¦}}

4) **{{ë§ˆìŠ¤í„° í† í”½ ì œëª©}}**
- **Why now:** {{â€¦}}

5) **{{ë§ˆìŠ¤í„° í† í”½ ì œëª©}}**
- **Why now:** {{â€¦}}

[ê²€ì¦]
- topic_categoryëŠ” ë°˜ë“œì‹œ {topic_category}ë§Œ ì‚¬ìš©
- ì •í™•íˆ 5ê°œì¸ì§€ í™•ì¸
- Why nowê°€ ëª¨ë‘ 'ì§€ê¸ˆ ì‹œì ' ê´€ì ìœ¼ë¡œ ì„¤ëª…ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸

ì´ ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ì•Šìœ¼ë©´ ì¬ìƒì„±í•˜ë¼."""

        try:
            # ì¬ì‹œë„ ë¡œì§ (ìµœëŒ€ 1íšŒ)
            max_retries = 1
            for attempt in range(max_retries + 1):
                try:
                    response = self.client.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": "You are a data-driven content strategist specializing in creating master topics for LG Electronics blog and social media content."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.7,
                        max_tokens=2000
                    )
                    return response.choices[0].message.content.strip()
                except (RateLimitError, APIConnectionError, APITimeoutError) as e:
                    if attempt < max_retries:
                        wait_time = (attempt + 1) * 2  # 2ì´ˆ, 4ì´ˆ ëŒ€ê¸°
                        print(f"Retry {attempt + 1}/{max_retries} after {wait_time}s: {e}")
                        time.sleep(wait_time)
                        continue
                    else:
                        raise
                        
        except (APIError, RateLimitError, APIConnectionError, APITimeoutError) as e:
            print(f"Error calling GPT API for master topics ({topic_category}): {e}")
            return None
        except Exception as e:
            print(f"Unexpected error in generate_master_topics ({topic_category}): {e}")
            return None
    
    def _get_model_name(self) -> str:
        """ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸° (í™˜ê²½ë³€ìˆ˜ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)"""
        return os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    
    def generate_hs_insight(
        self,
        topic_category: str,
        master_topic_kr: str,
        master_topic_en: str,
        why_now_kr: str,
        why_now_en: str,
        content_angle: str,
        related_topics: List[str]
    ) -> Tuple[Optional[str], Optional[str]]:
        """
        LGì „ì HS ì½˜í…ì¸  ì¸ì‚¬ì´íŠ¸ ìƒì„±
        
        Args:
            topic_category: í† í”½ ì¹´í…Œê³ ë¦¬
            master_topic_kr: ë§ˆìŠ¤í„° í† í”½ (í•œêµ­ì–´)
            master_topic_en: ë§ˆìŠ¤í„° í† í”½ (ì˜ì–´)
            why_now_kr: Why Now (í•œêµ­ì–´)
            why_now_en: Why Now (ì˜ì–´)
            content_angle: ì½˜í…ì¸  ì•µê¸€
            related_topics: ì—°ê´€ ì£¼ì œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            Tuple[Optional[str], Optional[str]]: (ì¸ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸, ì—ëŸ¬ ë©”ì‹œì§€)
            - ì„±ê³µ ì‹œ: (ì¸ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸, None)
            - ì‹¤íŒ¨ ì‹œ: (None, ì—ëŸ¬ ë©”ì‹œì§€)
        """
        if not is_openai_available():
            error_msg = "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            logger.error(error_msg)
            return None, error_msg
        
        # ì—°ê´€ ì£¼ì œ í¬ë§·íŒ… (ë¹ˆ ê°’ ì²˜ë¦¬)
        if related_topics and len(related_topics) > 0:
            related_topics_text = ", ".join([str(t) for t in related_topics[:3] if t])
        else:
            related_topics_text = "None"
        
        # ë¹ˆ ê°’ ì•ˆì „ ì²˜ë¦¬
        topic_category = topic_category or "N/A"
        master_topic_kr = master_topic_kr or "N/A"
        master_topic_en = master_topic_en or ""
        why_now_kr = why_now_kr or ""
        why_now_en = why_now_en or ""
        content_angle = content_angle or ""
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """ë„ˆëŠ” LGì „ì HS(ìƒí™œê°€ì „) ê´€ì ì˜ ì½˜í…ì¸  ì „ëµê°€ë‹¤.
ì•„ë˜ "ë§ˆìŠ¤í„° í† í”½" ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì œí’ˆ ì§ì ‘ í™ë³´ê°€ ì•„ë‹Œ
'ë´„ ì‹œì¦Œ ì£¼ë°© ì‚¬ìš© ë§¥ë½(í–‰ë™/ë£¨í‹´/ë¬¸ì œ)ì„ ì„ ì í•˜ëŠ” ì½˜í…ì¸  ì•µì»¤' ê´€ì ì—ì„œ
ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•´ë¼.

ê·œì¹™:
- "Reddit" ê°™ì€ ë°ì´í„° ì¶œì²˜ë¥¼ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ
- ì œí’ˆëª…/ëª¨ë¸ëª… ì§ì ‘ ì–¸ê¸‰ ê¸ˆì§€(ê´‘ê³ ì²˜ëŸ¼ ë³´ì´ë©´ ì‹¤íŒ¨)
- ê¸°ëŠ¥ ë‚˜ì—´ ê¸ˆì§€(ìƒí™œ ì‹œë‚˜ë¦¬ì˜¤/ë£¨í‹´ ì¤‘ì‹¬ìœ¼ë¡œ ì œì•ˆ)
- ê³¼ì¥ ê¸ˆì§€, ì‹¤í–‰ ê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œë§Œ ì œì•ˆ
- ì•„ë˜ ì¶œë ¥ í¬ë§·ì„ ì •í™•íˆ ì¤€ìˆ˜"""
        
        # ìœ ì € í”„ë¡¬í”„íŠ¸
        user_prompt = f"""ì…ë ¥:
[Topic Category] {topic_category}
[Title KR] {master_topic_kr}
[Title EN] {master_topic_en}
[Why Now KR] {why_now_kr}
[Why Now EN] {why_now_en}
[Content Angle] {content_angle}
[Related Topics] {related_topics_text}

ì¶œë ¥ í¬ë§·(Markdown):
### ğŸ“Œ LG HS Strategic Content Insight

**A. Consumer Transition Signal**
- (3~5ì¤„)

**B. HS Context / Home Workflow**
- (3~5ì¤„)

**C. Content Activation Plan**
- Blog: (2~3ì¤„)
- Social: (2~3ì¤„)
- Campaign: (2~3ì¤„)

**D. Measurement Ideas**
- (ì§€í‘œ 3ê°œ, ì¸¡ì • ë°©ì‹ í¬í•¨)

**E. Risks & Guardrails**
- (ì£¼ì˜/ê°€ì´ë“œ 3ê°œ)"""
        
        try:
            # í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)
            try:
                client = self.client
                logger.debug("OpenAI client initialized successfully")
            except ValueError as e:
                error_msg = str(e)
                logger.exception("OpenAI client initialization error")
                if "OPENAI_API_KEY" in error_msg:
                    error_msg = "API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."
                return None, error_msg
            except Exception as e:
                logger.exception("Unexpected error getting OpenAI client")
                return None, f"í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {type(e).__name__}: {str(e)}"
            
            # ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
            model_name = self._get_model_name()
            logger.debug(f"Calling GPT API with model: {model_name}")
            logger.debug(f"Topic: {master_topic_kr[:50]}...")
            
            # ì¬ì‹œë„ ë¡œì§ (ìµœëŒ€ 2íšŒ, ì§§ì€ ë°±ì˜¤í”„)
            max_retries = 2
            timeout_seconds = int(os.getenv("OPENAI_TIMEOUT", "60"))
            
            for attempt in range(max_retries + 1):
                try:
                    response = client.chat.completions.create(
                        model=model_name,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=2000,
                        timeout=timeout_seconds
                    )
                    result = response.choices[0].message.content.strip()
                    logger.info(f"GPT API call successful. Response length: {len(result)}")
                    return result, None
                    
                except AuthenticationError as e:
                    error_msg = f"ì¸ì¦ ì˜¤ë¥˜ (401): API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                    logger.exception("Authentication error")
                    return None, error_msg
                    
                except RateLimitError as e:
                    if attempt < max_retries:
                        wait_time = (attempt + 1) * 2  # 2ì´ˆ, 4ì´ˆ ëŒ€ê¸°
                        logger.warning(f"Rate limit error, retrying after {wait_time}s (attempt {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                    else:
                        error_msg = "API ì‚¬ìš©ëŸ‰ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        logger.exception("Rate limit error (max retries exceeded)")
                        return None, error_msg
                        
                except APITimeoutError as e:
                    if attempt < max_retries:
                        wait_time = (attempt + 1) * 2
                        logger.warning(f"Timeout error, retrying after {wait_time}s (attempt {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                    else:
                        error_msg = f"ìš”ì²­ ì‹œê°„ ì´ˆê³¼ ({timeout_seconds}ì´ˆ). ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        logger.exception("Timeout error (max retries exceeded)")
                        return None, error_msg
                        
                except APIConnectionError as e:
                    if attempt < max_retries:
                        wait_time = (attempt + 1) * 2
                        logger.warning(f"Connection error, retrying after {wait_time}s (attempt {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                    else:
                        error_msg = "ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                        logger.exception("Connection error (max retries exceeded)")
                        return None, error_msg
                        
                except APIError as e:
                    error_type = type(e).__name__
                    status_code = getattr(e, 'status_code', None)
                    
                    if status_code == 400:
                        error_msg = f"ì˜ëª»ëœ ìš”ì²­ (400): ìš”ì²­ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
                    elif status_code == 401:
                        error_msg = f"ì¸ì¦ ì˜¤ë¥˜ (401): API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                    elif status_code == 429:
                        error_msg = f"ì‚¬ìš©ëŸ‰ ì œí•œ (429): API ì‚¬ìš©ëŸ‰ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤."
                    else:
                        error_msg = f"API ì˜¤ë¥˜ ({status_code or error_type}): {str(e)}"
                    
                    logger.exception(f"API error ({error_type}, status={status_code})")
                    return None, error_msg
                    
            # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
            error_msg = "ëª¨ë“  ì¬ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            logger.error(error_msg)
            return None, error_msg
            
        except Exception as e:
            error_type = type(e).__name__
            error_msg = f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ({error_type}): {str(e)}"
            logger.exception("Unexpected error in generate_hs_insight")
            return None, error_msg


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_gpt_service: Optional[GPTService] = None


def get_gpt_service() -> GPTService:
    """GPT ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _gpt_service
    
    # í´ë˜ìŠ¤ ë ˆë²¨ì—ì„œ ë©”ì„œë“œ ì¡´ì¬ í™•ì¸
    if not hasattr(GPTService, 'generate_hs_insight'):
        import logging
        logger = logging.getLogger(__name__)
        logger.error("GPTService class missing generate_hs_insight method! This indicates a code loading issue.")
        raise AttributeError(
            "GPTService class does not have generate_hs_insight method. "
            "This usually means Streamlit is using a cached version of the module. "
            "Please restart Streamlit completely (stop and restart)."
        )
    
    # ì¸ìŠ¤í„´ìŠ¤ ë ˆë²¨ì—ì„œ ë©”ì„œë“œ ì¡´ì¬ í™•ì¸ ë° ê°•ì œ ë¦¬ì…‹
    if _gpt_service is not None:
        if not hasattr(_gpt_service, 'generate_hs_insight'):
            # ì´ì „ ë²„ì „ì˜ ì¸ìŠ¤í„´ìŠ¤ê°€ ìºì‹œë˜ì–´ ìˆìŒ - ê°•ì œ ë¦¬ì…‹
            import logging
            logger = logging.getLogger(__name__)
            logger.warning("GPT service instance missing generate_hs_insight method, resetting instance...")
            _gpt_service = None
    
    if _gpt_service is None:
        _gpt_service = GPTService()
        # ìƒì„± í›„ ë©”ì„œë“œ ì¡´ì¬ í™•ì¸
        if not hasattr(_gpt_service, 'generate_hs_insight'):
            import logging
            logger = logging.getLogger(__name__)
            logger.error("New GPT service instance also missing generate_hs_insight method!")
            raise AttributeError(
                "GPTService instance does not have generate_hs_insight method. "
                "Please restart Streamlit completely (Ctrl+C to stop, then restart)."
            )
    
    return _gpt_service


def reset_gpt_service():
    """GPT ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì…‹ (í…ŒìŠ¤íŠ¸/ë””ë²„ê¹…ìš©)"""
    global _gpt_service
    _gpt_service = None
