# DB ì ì¬ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ ë° ìˆ˜ì •ì•ˆ

## [1] ì €ì¥ ê²½ë¡œ ì¶”ì  (Call Chain)

### ì „ì²´ íë¦„
```
Apify Actor ì‹¤í–‰ (MCP ë˜ëŠ” API)
  â†“
save_all_keywords_api.py:114 save_dataset()
  â†“
save_all_keywords_api.py:136 fetch_dataset_items()  # Apify API í˜¸ì¶œ
  â†“
save_all_keywords_api.py:144 process_apify_results(items, keyword, run_id)
  â†“
worker/pipeline/process_apify_results.py:114 upsert_reddit_posts_batch()
  â†“
worker/pipeline/db.py:239 upsert_reddit_posts_batch()
  â†“
worker/pipeline/db.py:61 get_db_connection()  # Connection pool ë˜ëŠ” ì§ì ‘ ì—°ê²°
  â†“
PostgreSQL INSERT/UPDATE ì‹¤í–‰
```

### ì‹¤í–‰ í™˜ê²½
- **ì„œë¹„ìŠ¤**: Railway Worker ì„œë¹„ìŠ¤ (`worker/main.py`)
- **ì‹¤í–‰ ëª…ë ¹**: `python -m worker.main` (railway-worker.json)
- **ëª¨ë“œ**: `WORKER_MODE=save_keywords` (ë˜ëŠ” ì§ì ‘ `save_all_keywords_api.py` ì‹¤í–‰)

### í•µì‹¬ íŒŒì¼ ë° ë¼ì¸
1. **ì§„ì…ì **: `save_all_keywords_api.py:114` (`save_dataset()`)
2. **ë°ì´í„° ì²˜ë¦¬**: `worker/pipeline/process_apify_results.py:11` (`process_apify_results()`)
3. **DB ì €ì¥**: `worker/pipeline/db.py:239` (`upsert_reddit_posts_batch()`)
4. **ì—°ê²° ê´€ë¦¬**: `worker/pipeline/db.py:28` (`get_connection_pool()`), `worker/pipeline/db.py:61` (`get_db_connection()`)

---

## [2] ì‹¤íŒ¨ ë¡œê·¸ í•µì‹¬ (ì˜ˆìƒ ì—ëŸ¬ ìœ í˜•)

### A. ì—°ê²°/ì¸ì¦ ë¬¸ì œ
**ì˜ˆìƒ ì—ëŸ¬ ë©”ì‹œì§€**:
```
psycopg2.OperationalError: SSL connection required
psycopg2.OperationalError: connection to server at "xxx.railway.app" failed
psycopg2.OperationalError: FATAL: password authentication failed
```

**ë°œìƒ ìœ„ì¹˜**: `worker/pipeline/db.py:48-58` (connection pool ìƒì„±)

### B. ìŠ¤í‚¤ë§ˆ/ì œì•½ì¡°ê±´ ë¬¸ì œ
**ì˜ˆìƒ ì—ëŸ¬ ë©”ì‹œì§€**:
```
psycopg2.errors.UndefinedTable: relation "raw_reddit_posts" does not exist
psycopg2.errors.UndefinedColumn: column "xxx" does not exist
psycopg2.errors.NotNullViolation: null value in column "xxx" violates not-null constraint
```

**ë°œìƒ ìœ„ì¹˜**: `worker/pipeline/db.py:289` (INSERT ì‹¤í–‰)

### C. ë°ì´í„° ì •í•©ì„± ë¬¸ì œ
**ì˜ˆìƒ ì—ëŸ¬ ë©”ì‹œì§€**:
```
psycopg2.errors.StringDataRightTruncation: value too long for type VARCHAR(50)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type bigint
```

**ë°œìƒ ìœ„ì¹˜**: `worker/pipeline/db.py:266-279` (ë°ì´í„° ì¤€ë¹„), `worker/pipeline/db.py:289` (INSERT ì‹¤í–‰)

### D. íŠ¸ëœì­ì…˜/ë½ ë¬¸ì œ
**ì˜ˆìƒ ì—ëŸ¬ ë©”ì‹œì§€**:
```
psycopg2.errors.DeadlockDetected: deadlock detected
psycopg2.errors.QueryCanceled: canceling statement due to statement_timeout
```

**ë°œìƒ ìœ„ì¹˜**: `worker/pipeline/db.py:302` (commit)

---

## [3] ì›ì¸ í›„ë³´ Top 3 (ê·¼ê±° í¬í•¨)

### ğŸ”´ ì›ì¸ 1ìˆœìœ„: Railway PostgreSQL SSL ì„¤ì • ëˆ„ë½ (A. ì—°ê²°/ì¸ì¦ ë¬¸ì œ)

**ê·¼ê±°**:
1. **ì½”ë“œ í™•ì¸**: `worker/pipeline/db.py:44-46`ì—ì„œ Railway URL ê°ì§€ ì‹œ SSL ì¶”ê°€í•˜ì§€ë§Œ, ì¡°ê±´ì´ ë¶ˆì™„ì „:
   ```python
   if 'railway' in database_url.lower() and 'sslmode' not in database_url:
   ```
   - `railway` ë¬¸ìì—´ì´ URLì— ì—†ì„ ìˆ˜ ìˆìŒ (ì˜ˆ: `crossover.proxy.rlwy.net`)
   - `sslmode`ê°€ ì´ë¯¸ ìˆì§€ë§Œ ì˜ëª»ëœ ê°’ì¼ ìˆ˜ ìˆìŒ

2. **í™˜ê²½ ë³€ìˆ˜ ë¶ˆì¼ì¹˜**: 
   - `common/config.py:14`: `DATABASE_URL` ë˜ëŠ” `RAILWAY_DATABASE_URL`ë§Œ í™•ì¸
   - `worker/pipeline/db.py:34-38`: ë” ë§ì€ ë³€ìˆ˜ í™•ì¸ (`POSTGRES_URL`, `POSTGRES_PRIVATE_URL`)
   - ë‘ ëª¨ë“ˆì´ ë‹¤ë¥¸ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì½ì„ ìˆ˜ ìˆìŒ

3. **Connection Pool ì´ˆê¸°í™” ì‹¤íŒ¨**: 
   - `worker/pipeline/db.py:50-54`ì—ì„œ pool ìƒì„± ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
   - Fallback ë¡œì§(`worker/pipeline/db.py:69-78`)ì´ ìˆì§€ë§Œ SSL ì„¤ì •ì´ ì—†ì„ ìˆ˜ ìˆìŒ

**í™•ì •ì„ ìœ„í•œ ì¶”ê°€ ë¡œê·¸**:
```python
logger.info(f"Database URL (masked): {database_url[:50]}...")
logger.info(f"SSL mode in URL: {'sslmode' in database_url}")
```

### ğŸŸ¡ ì›ì¸ 2ìˆœìœ„: í™˜ê²½ ë³€ìˆ˜ ìŠ¤ì½”í”„ ë¬¸ì œ (G. ì‹¤í–‰ í™˜ê²½ ë¬¸ì œ)

**ê·¼ê±°**:
1. **Railway ì„œë¹„ìŠ¤ë³„ ë³€ìˆ˜ ìŠ¤ì½”í”„**:
   - Worker ì„œë¹„ìŠ¤ì— `DATABASE_URL`ì´ ì œëŒ€ë¡œ ì£¼ì…ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ
   - PostgreSQL ì„œë¹„ìŠ¤ê°€ ì—¬ëŸ¬ ê°œì¼ ê²½ìš° (`Postgres`, `Postgres-tezK`) ì˜ëª»ëœ ì„œë¹„ìŠ¤ì˜ URLì„ ì½ì„ ìˆ˜ ìˆìŒ

2. **í™˜ê²½ ë³€ìˆ˜ ì½ê¸° ìˆœì„œ ë¶ˆì¼ì¹˜**:
   - `common/config.py:14`: `DATABASE_URL` â†’ `RAILWAY_DATABASE_URL`
   - `worker/pipeline/db.py:34-38`: `DATABASE_URL` â†’ `RAILWAY_DATABASE_URL` â†’ `POSTGRES_URL` â†’ `POSTGRES_PRIVATE_URL`
   - ë‘ ëª¨ë“ˆì´ ë‹¤ë¥¸ ê°’ì„ ì½ì„ ìˆ˜ ìˆìŒ

**í™•ì •ì„ ìœ„í•œ ì¶”ê°€ ë¡œê·¸**:
```python
logger.info(f"Env vars: DATABASE_URL={bool(os.getenv('DATABASE_URL'))}, "
            f"RAILWAY_DATABASE_URL={bool(os.getenv('RAILWAY_DATABASE_URL'))}, "
            f"POSTGRES_URL={bool(os.getenv('POSTGRES_URL'))}")
```

### ğŸŸ¢ ì›ì¸ 3ìˆœìœ„: Connection Pool ë¦¬ì†ŒìŠ¤ ëˆ„ìˆ˜/íƒ€ì„ì•„ì›ƒ (E. ORM/ë“œë¼ì´ë²„ ì‚¬ìš© ì˜¤ë¥˜)

**ê·¼ê±°**:
1. **Pool ë°˜í™˜ ëˆ„ë½ ê°€ëŠ¥ì„±**:
   - `upsert_reddit_posts_batch()`ì—ì„œ ì˜ˆì™¸ ë°œìƒ ì‹œ `put_db_connection()` í˜¸ì¶œì€ `finally`ì— ìˆìŒ (ì •ìƒ)
   - í•˜ì§€ë§Œ `conn.close()` ëŒ€ì‹  `put_db_connection()`ì„ í˜¸ì¶œí•´ì•¼ í•˜ëŠ”ë°, ì¼ë¶€ í•¨ìˆ˜ì—ì„œ `conn.close()` ì§ì ‘ í˜¸ì¶œ (ì˜ˆ: `upsert_gsc_query:408`)

2. **ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ íƒ€ì„ì•„ì›ƒ**:
   - `execute_batch()`ì—ì„œ ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ `statement_timeout` ì´ˆê³¼ ê°€ëŠ¥
   - Railway PostgreSQL ê¸°ë³¸ íƒ€ì„ì•„ì›ƒì´ ì§§ì„ ìˆ˜ ìˆìŒ

**í™•ì •ì„ ìœ„í•œ ì¶”ê°€ ë¡œê·¸**:
```python
logger.info(f"Pool stats: minconn={pool.minconn}, maxconn={pool.maxconn}")
logger.info(f"Batch size: {len(insert_data)}")
```

---

## [4] ìˆ˜ì •ì•ˆ (ìµœì†Œ ë³€ê²½ + ì•ˆì „ì¥ì¹˜)

### ìˆ˜ì • 1: Railway PostgreSQL SSL ì„¤ì • ê°•í™”

**íŒŒì¼**: `worker/pipeline/db.py`

**ë³€ê²½ ë‚´ìš©**:
1. Railway URL ê°ì§€ ë¡œì§ ê°œì„  (ë” ë„“ì€ íŒ¨í„´ ë§¤ì¹­)
2. SSL ì„¤ì •ì´ ì—†ìœ¼ë©´ ë¬´ì¡°ê±´ ì¶”ê°€
3. ì—°ê²° ì‹¤íŒ¨ ì‹œ ìƒì„¸ ë¡œê·¸ ì¶”ê°€

```python
def get_connection_pool():
    """Get or create connection pool"""
    global _connection_pool
    if _connection_pool is None:
        with _pool_lock:
            if _connection_pool is None:
                database_url = (
                    os.getenv("DATABASE_URL") or 
                    os.getenv("RAILWAY_DATABASE_URL") or
                    os.getenv("POSTGRES_URL") or
                    os.getenv("POSTGRES_PRIVATE_URL")
                )
                if not database_url:
                    raise ValueError("DATABASE_URL not found in environment variables")
                
                # Railway PostgreSQL SSL ì„¤ì • ê°•í™”
                # Railway URL íŒ¨í„´: *.railway.app, *.proxy.rlwy.net, *.up.railway.app
                is_railway = any(pattern in database_url.lower() for pattern in [
                    'railway.app', 'rlwy.net', 'up.railway.app'
                ])
                
                if is_railway:
                    # SSL ëª¨ë“œ í™•ì¸ ë° ì¶”ê°€
                    if 'sslmode' not in database_url.lower():
                        separator = '&' if '?' in database_url else '?'
                        database_url = f"{database_url}{separator}sslmode=require"
                        logger.info("Added sslmode=require to Railway database URL")
                    elif 'sslmode=disable' in database_url.lower():
                        # sslmode=disableì´ë©´ requireë¡œ ë³€ê²½
                        database_url = database_url.replace('sslmode=disable', 'sslmode=require')
                        logger.warning("Changed sslmode from disable to require for Railway")
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë¡œê·¸ (ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹)
                url_masked = database_url.split('@')[-1] if '@' in database_url else database_url[:50]
                logger.info(f"Connecting to database: ...@{url_masked}")
                logger.debug(f"SSL mode: {'sslmode' in database_url.lower()}")
                
                try:
                    # Connection pool ìƒì„± (min 2, max 10)
                    _connection_pool = psycopg2.pool.ThreadedConnectionPool(
                        minconn=2,
                        maxconn=10,
                        dsn=database_url,
                        connect_timeout=10  # ì—°ê²° íƒ€ì„ì•„ì›ƒ 10ì´ˆ
                    )
                    logger.info("Connection pool created successfully")
                except Exception as e:
                    logger.error(f"Failed to create connection pool: {e}")
                    logger.error(f"Database URL pattern: {url_masked}")
                    raise
    return _connection_pool
```

### ìˆ˜ì • 2: ë°°ì¹˜ ì²˜ë¦¬ ì•ˆì „ì¥ì¹˜ ê°•í™”

**íŒŒì¼**: `worker/pipeline/db.py`

**ë³€ê²½ ë‚´ìš©**:
1. ë°°ì¹˜ í¬ê¸° ì œí•œ (í•œ ë²ˆì— ë„ˆë¬´ ë§ì€ ë°ì´í„° ì²˜ë¦¬ ë°©ì§€)
2. ì¬ì‹œë„ ë¡œì§ ì ìš©
3. ìƒì„¸ ì—ëŸ¬ ë¡œê¹…

```python
def upsert_reddit_posts_batch(posts_data: List[Dict[str, Any]], run_id: int) -> Dict[str, int]:
    """Batch upsert Reddit posts (ì„±ëŠ¥ ê°œì„ )"""
    if not posts_data:
        return {"inserted": 0, "updated": 0, "errors": 0}
    
    # ë°°ì¹˜ í¬ê¸° ì œí•œ (í•œ ë²ˆì— ìµœëŒ€ 500ê°œ)
    BATCH_SIZE_LIMIT = 500
    if len(posts_data) > BATCH_SIZE_LIMIT:
        logger.warning(f"Batch size {len(posts_data)} exceeds limit {BATCH_SIZE_LIMIT}, splitting...")
        # ì¬ê·€ì ìœ¼ë¡œ ë¶„í•  ì²˜ë¦¬
        stats = {"inserted": 0, "updated": 0, "errors": 0}
        for i in range(0, len(posts_data), BATCH_SIZE_LIMIT):
            batch = posts_data[i:i + BATCH_SIZE_LIMIT]
            batch_stats = upsert_reddit_posts_batch(batch, run_id)
            stats["inserted"] += batch_stats["inserted"]
            stats["updated"] += batch_stats["updated"]
            stats["errors"] += batch_stats["errors"]
        return stats
    
    conn = None
    stats = {"inserted": 0, "updated": 0, "errors": 0}
    
    @retry_db_operation(max_retries=3, backoff=2.0)
    def _execute_batch_insert():
        nonlocal conn, stats, insert_data
        
        conn = get_db_connection()
        cur = conn.cursor()
        
        try:
            # ë°°ì¹˜ INSERT
            execute_batch(cur, """
                INSERT INTO raw_reddit_posts (
                    reddit_post_id, subreddit, title, body, author,
                    created_utc, upvotes, num_comments, permalink, url,
                    keyword, raw_json
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (reddit_post_id) DO UPDATE SET
                    upvotes = EXCLUDED.upvotes,
                    num_comments = EXCLUDED.num_comments,
                    updated_at = CURRENT_TIMESTAMP
            """, insert_data, page_size=100)
            
            stats["inserted"] = len(insert_data)
            conn.commit()
            logger.info(f"Batch upserted {stats['inserted']} posts, {stats['errors']} errors")
            
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"Batch insert error: {e}", exc_info=True)
            # ì²« ë²ˆì§¸ ì‹¤íŒ¨í•œ ë ˆì½”ë“œ ìƒ˜í”Œ ë¡œê¹…
            if insert_data:
                sample = insert_data[0]
                logger.error(f"Sample data (first record): post_id={sample[0]}, "
                           f"title_len={len(sample[2]) if sample[2] else 0}, "
                           f"body_len={len(sample[3]) if sample[3] else 0}")
            raise
    
    try:
        # ë°°ì¹˜ ì²˜ë¦¬ìš© ë°ì´í„° ì¤€ë¹„
        insert_data = []
        import time as time_module
        
        for post_data in posts_data:
            try:
                post_id = str(post_data.get('id', '')).strip()
                if not post_id:
                    stats["errors"] += 1
                    continue
                
                created_utc = post_data.get('created_utc', 0)
                if not isinstance(created_utc, int) or created_utc <= 0:
                    created_utc = int(time_module.time())
                
                insert_data.append((
                    post_id,
                    (post_data.get('subreddit', '') or 'unknown')[:100],
                    (post_data.get('title', '') or 'Untitled')[:10000],
                    (post_data.get('selftext', '') or '')[:50000] or None,
                    (post_data.get('author', '') or '')[:100] or None,
                    created_utc,
                    max(0, int(post_data.get('ups', 0))),
                    max(0, int(post_data.get('num_comments', 0))),
                    (post_data.get('permalink', '') or '')[:5000] or None,
                    (post_data.get('url', '') or '')[:5000] or None,
                    (post_data.get('keyword', '') or '')[:200],
                    Json(post_data)
                ))
            except Exception as e:
                logger.error(f"Error preparing post data {post_data.get('id', 'unknown')}: {e}")
                stats["errors"] += 1
                continue
        
        if not insert_data:
            return stats
        
        # ë°°ì¹˜ INSERT ì‹¤í–‰ (ì¬ì‹œë„ í¬í•¨)
        _execute_batch_insert()
        
    except Exception as e:
        logger.error(f"Batch upsert error (final): {e}", exc_info=True)
        stats["errors"] = len(posts_data) - stats["inserted"]
        # ì—ëŸ¬ë¥¼ ë‹¤ì‹œ raiseí•˜ì§€ ì•Šê³  í†µê³„ë§Œ ë°˜í™˜ (ë¶€ë¶„ ì„±ê³µ í—ˆìš©)
        # raise  # ì£¼ì„ ì²˜ë¦¬: ë¶€ë¶„ ì„±ê³µ í—ˆìš©
    finally:
        if conn:
            put_db_connection(conn)
    
    return stats
```

### ìˆ˜ì • 3: í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ë¡œì§ í†µì¼

**íŒŒì¼**: `common/config.py`

**ë³€ê²½ ë‚´ìš©**:
1. `worker/pipeline/db.py`ì™€ ë™ì¼í•œ í™˜ê²½ ë³€ìˆ˜ ì½ê¸° ìˆœì„œ ì ìš©
2. ë¡œê¹… ì¶”ê°€

```python
# Database ì„¤ì •
DATABASE_URL = (
    os.getenv("DATABASE_URL") or 
    os.getenv("RAILWAY_DATABASE_URL") or
    os.getenv("POSTGRES_URL") or
    os.getenv("POSTGRES_PRIVATE_URL")
)
```

---

## [5] ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë¡œì»¬ ê²€ì¦

1. **í™˜ê²½ ë³€ìˆ˜ í™•ì¸**:
```bash
# Railway DATABASE_URL ë³µì‚¬ í›„ ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸
export DATABASE_URL="postgresql://postgres:xxx@xxx.railway.app:5432/railway"
python -c "from worker.pipeline.db import get_db_connection; conn = get_db_connection(); print('âœ… ì—°ê²° ì„±ê³µ'); conn.close()"
```

2. **SSL ì—°ê²° í…ŒìŠ¤íŠ¸**:
```bash
# SSL ëª¨ë“œ í™•ì¸
python -c "
import os
url = os.getenv('DATABASE_URL', '')
print(f'SSL mode in URL: {\"sslmode\" in url.lower()}')
print(f'URL pattern: {url[:50]}...')
"
```

3. **ë°°ì¹˜ ì €ì¥ í…ŒìŠ¤íŠ¸**:
```python
# test_batch_save.py
from worker.pipeline.db import create_pipeline_run, upsert_reddit_posts_batch

run_id = create_pipeline_run("test", "running")
test_posts = [
    {
        'id': 'test_1',
        'subreddit': 'test',
        'title': 'Test Post',
        'selftext': 'Test body',
        'author': 'testuser',
        'created_utc': 1234567890,
        'ups': 10,
        'num_comments': 5,
        'permalink': '/r/test/test_1',
        'url': 'https://reddit.com/r/test/test_1',
        'keyword': 'test keyword'
    }
]
stats = upsert_reddit_posts_batch(test_posts, run_id)
print(f"âœ… ì €ì¥ ì™„ë£Œ: {stats}")
```

### Railway ë°°í¬ í›„ í™•ì¸

1. **Worker ë¡œê·¸ í™•ì¸**:
```bash
# Railway ëŒ€ì‹œë³´ë“œ > Worker ì„œë¹„ìŠ¤ > Logs
# ë‹¤ìŒ ë©”ì‹œì§€ í™•ì¸:
# - "Connection pool created successfully"
# - "Added sslmode=require to Railway database URL" (í•„ìš”ì‹œ)
# - "Batch upserted X posts"
```

2. **ì—ëŸ¬ ë¡œê·¸ í™•ì¸**:
```bash
# ë‹¤ìŒ ì—ëŸ¬ê°€ ì—†ëŠ”ì§€ í™•ì¸:
# - "Failed to create connection pool"
# - "Batch insert error"
# - "SSL connection required"
```

3. **ë°ì´í„° í™•ì¸**:
```sql
-- Railway PostgreSQL ì¿¼ë¦¬ ì‹¤í–‰
SELECT COUNT(*) FROM raw_reddit_posts;
SELECT keyword, COUNT(*) FROM raw_reddit_posts GROUP BY keyword ORDER BY COUNT(*) DESC LIMIT 10;
```

4. **í™˜ê²½ ë³€ìˆ˜ í™•ì¸**:
```bash
# Railway ëŒ€ì‹œë³´ë“œ > Worker ì„œë¹„ìŠ¤ > Variables
# ë‹¤ìŒ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸:
# - DATABASE_URL (ë˜ëŠ” RAILWAY_DATABASE_URL)
# - APIFY_API_TOKEN (save_keywords ëª¨ë“œ ì‚¬ìš© ì‹œ)
```

5. **í—¬ìŠ¤ì²´í¬**:
```python
# Railway Worker ì„œë¹„ìŠ¤ì—ì„œ ì‹¤í–‰
python -c "
from worker.pipeline.db import get_db_connection, check_pgvector_available
conn = get_db_connection()
cur = conn.cursor()
cur.execute('SELECT 1')
print('âœ… DB ì—°ê²° ì„±ê³µ')
cur.close()
conn.close()
"
```

---

## ì¶”ê°€ ê¶Œì¥ì‚¬í•­

### 1. ì—ëŸ¬ ëª¨ë‹ˆí„°ë§ ê°•í™”
- ì‹¤íŒ¨í•œ ë ˆì½”ë“œë¥¼ ë³„ë„ í…Œì´ë¸”(`failed_reddit_posts`)ì— ì €ì¥
- Railway ë¡œê·¸ì— ì—ëŸ¬ ì•Œë¦¼ ì„¤ì •

### 2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ë°°ì¹˜ ì²˜ë¦¬ ì‹œê°„ ë¡œê¹…
- Connection pool ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§

### 3. ì¬ì‹œë„ ì •ì±…
- í˜„ì¬ `@retry_db_operation` ë°ì½”ë ˆì´í„° ì‚¬ìš© ì¤‘ (ì¢‹ìŒ)
- ë°°ì¹˜ ì‹¤íŒ¨ ì‹œ ê°œë³„ ë ˆì½”ë“œ ì¬ì‹œë„ ì˜µì…˜ ì¶”ê°€ ê³ ë ¤
