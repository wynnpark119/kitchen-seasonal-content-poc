"""
Clustering Results ë·°

í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ í‘œì‹œ
"""
import streamlit as st
import pandas as pd
from typing import Optional

from services.clustering_service import get_clustering_service
from services.gpt_service import get_gpt_service
from common.openai_client import is_openai_available


def render_clustering_results():
    """Reddit í† í”½ ë¶„ì„ íƒ­ ë Œë”ë§"""
    clustering_service = get_clustering_service()
    gpt_service = get_gpt_service()
    
    try:
        clusters_df = clustering_service.get_all_clusters()
        
        if len(clusters_df) == 0:
            st.warning("âš ï¸ Reddit í† í”½ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("í´ëŸ¬ìŠ¤í„°ë§ì´ ì™„ë£Œë˜ë©´ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            return
        
        # ì¹´í…Œê³ ë¦¬ í•„í„°
        categories = clusters_df['topic_category'].dropna().unique()
        available_categories = sorted([cat for cat in categories if pd.notna(cat)])
        
        if available_categories:
            selected_category = st.selectbox(
                "ì¹´í…Œê³ ë¦¬ ì„ íƒ",
                ["All"] + available_categories,
                key="cluster_category_filter"
            )
            
            # í•„í„°ë§
            if selected_category == "All":
                filtered_df = clusters_df[clusters_df['topic_category'].notna()]
            else:
                filtered_df = clusters_df[clusters_df['topic_category'] == selected_category]
            
            # í´ëŸ¬ìŠ¤í„° í‘œì‹œ
            for idx, (_, cluster_row) in enumerate(filtered_df.iterrows()):
                cluster_id = cluster_row['cluster_id']
                cluster_id_str = str(cluster_id)
                cluster_name = cluster_row.get('cluster_name', f"Cluster_{cluster_id}")
                topic_category = cluster_row.get('topic_category')
                
                if pd.isna(topic_category) or topic_category is None:
                    topic_category_display = 'Unknown'
                else:
                    topic_category_display = topic_category
                
                size = cluster_row.get('size', 0)
                sub_cluster_index = cluster_row.get('sub_cluster_index')
                top_keywords = cluster_row.get('top_keywords', [])
                if not isinstance(top_keywords, list):
                    top_keywords = []
                
                with st.expander(f"ğŸ“Œ {cluster_name} ({topic_category_display})"):
                    # ê¸°ë³¸ ì •ë³´
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Cluster ID", cluster_id_str)
                    with col2:
                        st.metric("Size", int(size))
                    with col3:
                        st.metric("Sub Cluster Index", sub_cluster_index if pd.notna(sub_cluster_index) else "N/A")
                    with col4:
                        st.metric("Representative", int(cluster_row.get('representative_count', 0)))
                    
                    # ìš”ì•½ í‘œì‹œ
                    summary = cluster_row.get('summary')
                    if pd.notna(summary) and summary:
                        st.markdown("**ğŸ“ ìš”ì•½:**")
                        st.info(summary)
                    
                    # GPT ìš”ì•½ (ì„ íƒì , ì‹¤íŒ¨í•´ë„ í™”ë©´ ê¹¨ì§€ì§€ ì•ŠìŒ)
                    try:
                        if is_openai_available():
                            with st.spinner("GPTë¡œ í´ëŸ¬ìŠ¤í„° ìš”ì•½ ìƒì„± ì¤‘..."):
                                gpt_summary = gpt_service.generate_cluster_summary(
                                    cluster_id_str,
                                    top_keywords[:10] if top_keywords else [],
                                    int(size),
                                    topic_category_display if topic_category_display != 'Unknown' else 'Unknown'
                                )
                                if gpt_summary:
                                    st.markdown("**ğŸ“ ìš”ì•½ (GPT ìƒì„±):**")
                                    st.info(gpt_summary)
                    except Exception as gpt_error:
                        # GPT ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                        pass
                    
                    # Top Keywords
                    if top_keywords:
                        st.markdown("**ğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ:**")
                        keywords_str = ", ".join(top_keywords[:20])
                        st.write(keywords_str)
                        if len(top_keywords) > 20:
                            st.caption(f"ì´ {len(top_keywords)}ê°œ í‚¤ì›Œë“œ ì¤‘ ìƒìœ„ 20ê°œ í‘œì‹œ")
                    
                    # ëŒ€í‘œ í¬ìŠ¤íŠ¸
                    try:
                        representative_posts = clustering_service.get_representative_posts(cluster_id, limit=5)
                        
                        if len(representative_posts) > 0:
                            st.markdown("**ğŸ“Œ ëŒ€í‘œ í¬ìŠ¤íŠ¸:**")
                            for post_idx, (_, post_row) in enumerate(representative_posts.iterrows()):
                                with st.expander(f"Post {post_idx + 1}: {post_row.get('title', 'N/A')[:50]}..."):
                                    st.write(f"**Title**: {post_row.get('title', 'N/A')}")
                                    st.write(f"**Upvotes**: {post_row.get('upvotes', 0)}")
                                    st.write(f"**Comments**: {post_row.get('num_comments', 0)}")
                                    if post_row.get('permalink'):
                                        st.write(f"**Link**: https://reddit.com{post_row.get('permalink', '')}")
                    except Exception as e:
                        # ëŒ€í‘œ í¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                        pass
        else:
            st.info("Not available")
            
    except Exception as e:
        st.error(f"Error loading clustering results: {e}")
        st.info("Not available")


