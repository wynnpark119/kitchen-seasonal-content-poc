"""
Trend Explorer ë·°

SERP AI Overview / Trend Explorer í‘œì‹œ
"""
import streamlit as st
import pandas as pd

from services.serp_service import get_serp_service
from web.db_queries import parse_cited_sources


def render_trend_explorer():
    """êµ¬ê¸€ AI ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ íƒ­ ë Œë”ë§"""
    serp_service = get_serp_service()
    
    # í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ê´€ë¦¬
    if 'aio_display_count' not in st.session_state:
        st.session_state.aio_display_count = 20
    
    try:
        serp_df = serp_service.get_all_serp_data()
        
        if serp_df is None or len(serp_df) == 0:
            st.warning("âš ï¸ êµ¬ê¸€ AI ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ë©´ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            return
        
        # í†µê³„ ìš”ì•½
        filtered_df = serp_df[serp_df['aio_status'].isin(['AVAILABLE', 'NOT_AVAILABLE'])].copy()
        
        if len(filtered_df) == 0:
            st.warning("âš ï¸ í•„í„°ë§ëœ êµ¬ê¸€ AI ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("AVAILABLE ë˜ëŠ” NOT_AVAILABLE ìƒíƒœì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        col1, col2, col3 = st.columns(3)
        
        total_queries = len(filtered_df)
        available_count = len(filtered_df[filtered_df['aio_status'] == 'AVAILABLE'])
        not_available_count = len(filtered_df[filtered_df['aio_status'] == 'NOT_AVAILABLE'])
        
        with col1:
            st.metric("Total Queries", total_queries)
        with col2:
            st.metric("Available", f"{available_count} ({available_count/total_queries*100:.1f}%)" if total_queries > 0 else "0")
        with col3:
            st.metric("Not Available", f"{not_available_count} ({not_available_count/total_queries*100:.1f}%)" if total_queries > 0 else "0")
        
        st.markdown("---")
        
        # í˜„ì¬ í‘œì‹œí•  í•­ëª© ìˆ˜
        display_count = min(st.session_state.aio_display_count, len(filtered_df))
        display_df = filtered_df.head(display_count)
        
        # ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ë²ˆí˜¸ì™€ íƒœê·¸ í¬í•¨)
        for list_idx, (df_idx, row) in enumerate(display_df.iterrows(), start=1):
            # ë²ˆí˜¸ì™€ ì¿¼ë¦¬ ì œëª©
            expander_title = f"{list_idx}. {row['query']}"
            if pd.notna(row.get('snapshot_at')):
                expander_title += f" ({row['snapshot_at']})"
            
            # ìƒíƒœ íƒœê·¸ì™€ í•¨ê»˜ í‘œì‹œ
            col_tag, col_title = st.columns([1, 9])
            with col_tag:
                if row['aio_status'] == 'AVAILABLE':
                    st.markdown(f"<span style='background-color: #28a745; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.8em;'>Available</span>", unsafe_allow_html=True)
                else:
                    st.markdown(f"<span style='background-color: #dc3545; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.8em;'>Not Available</span>", unsafe_allow_html=True)
            with col_title:
                with st.expander(expander_title):
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown(f"**ğŸ” Query**: `{row['query']}`")
                    with col2:
                        if pd.notna(row.get('snapshot_at')):
                            st.caption(f"ğŸ“… {row['snapshot_at']}")
                    
                    # AI Overview í…ìŠ¤íŠ¸ ë˜ëŠ” ê²€ìƒ‰ ê²°ê³¼
                    if row['aio_status'] == 'AVAILABLE' and row.get('aio_text'):
                        st.markdown("**ğŸ“„ AI Overview:**")
                        st.info(row['aio_text'])
                    elif row.get('source_table') == 'serp_results':
                        st.markdown("**ğŸ“„ ê²€ìƒ‰ ê²°ê³¼:**")
                        sources = parse_cited_sources(row.get('cited_sources_json'))
                        if sources:
                            st.info(f"ì´ {len(sources)}ê°œì˜ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.")
                    
                    # ì°¸ê³  URL
                    sources = parse_cited_sources(row.get('cited_sources_json'))
                    if sources:
                        st.markdown("**ğŸ”— ì°¸ê³  URL:**")
                        
                        lg_sources = [s for s in sources if s.get('is_lg', False)]
                        non_lg_sources = [s for s in sources if not s.get('is_lg', False)]
                        
                        if lg_sources:
                            st.success(f"ğŸ  **LG ì¸ìš©**: {len(lg_sources)}ê°œ")
                            for source in lg_sources:
                                url = source.get('url', '#')
                                title = source.get('title', source.get('domain', 'N/A'))
                                snippet = source.get('snippet', '')
                                st.markdown(f"- **[{title}]({url})** ğŸ ")
                                if snippet:
                                    st.caption(f"  {snippet[:150]}...")
                        
                        if non_lg_sources:
                            st.markdown(f"**ê¸°íƒ€ ì°¸ê³  URL**: {len(non_lg_sources)}ê°œ")
                            for source in non_lg_sources[:10]:
                                url = source.get('url', '#')
                                title = source.get('title', source.get('domain', 'N/A'))
                                snippet = source.get('snippet', '')
                                position = source.get('position', '')
                                st.markdown(f"- **[{title}]({url})** {f'(ìœ„ì¹˜: {position})' if position else ''}")
                                if snippet:
                                    st.caption(f"  {snippet[:150]}...")
                            
                            if len(non_lg_sources) > 10:
                                st.caption(f"... ì™¸ {len(non_lg_sources) - 10}ê°œ ë”")
        
        # More ë²„íŠ¼ (ë” ë§ì€ í•­ëª© í‘œì‹œ)
        st.markdown("---")
        if display_count < len(filtered_df):
            remaining_count = len(filtered_df) - display_count
            if st.button(f"More ({remaining_count}ê°œ ë” ë³´ê¸°)", key="aio_more_button"):
                st.session_state.aio_display_count += 20
                st.rerun()
        else:
            st.info(f"ì „ì²´ {len(filtered_df)}ê°œ í•­ëª©ì„ ëª¨ë‘ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.")
            # ë¦¬ì…‹ ë²„íŠ¼
            if st.button("ì²˜ìŒë¶€í„° ë³´ê¸°", key="aio_reset_button"):
                st.session_state.aio_display_count = 20
                st.rerun()
        
        # CSV ë‹¤ìš´ë¡œë“œ
        st.markdown("---")
        csv = filtered_df.to_csv(index=False)
        st.download_button(
            "SERP ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
            csv,
            "serp_aio_data.csv",
            "text/csv",
            key="download_serp_csv"
        )
        
    except Exception as e:
        st.error(f"Error loading trend explorer data: {e}")
        st.info("Not available")
