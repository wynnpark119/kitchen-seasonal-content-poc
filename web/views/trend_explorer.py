"""
Trend Explorer ë·°

SERP AI Overview / Trend Explorer í‘œì‹œ
"""
import streamlit as st
import pandas as pd

from services.serp_service import get_serp_service
from web.db_queries import parse_cited_sources


def generate_channel_summary(lg_count: int, competitor_count: int, earned_count: int, other_count: int) -> str:
    """
    ì±„ë„ ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ ë¬¸êµ¬ ìƒì„±
    
    ê·œì¹™:
    - Competitor â‰¥ 3 â†’ "ëŒ€ì‘ í•„ìš”"
    - Earned â‰¥ 5 & LG Owned = 0 â†’ "ì½˜í…ì¸  ê¸°íšŒ ì˜ì—­"
    - LG Owned > 0 â†’ "LG ì±„ë„ ë…¸ì¶œ í™•ì¸"
    - Earned Media ë¹„ì¤‘ ë†’ìŒ â†’ "ë¸Œëœë“œ ê°œì… ì—¬ì§€ í° ì£¼ì œ"
    """
    total = lg_count + competitor_count + earned_count + other_count
    if total == 0:
        return ""
    
    summaries = []
    
    # ê²½ìŸì‚¬ ëŒ€ì‘ í•„ìš”
    if competitor_count >= 3:
        summaries.append("ê²½ìŸì‚¬ Owned ì½˜í…ì¸ ê°€ ë‹¤ìˆ˜ ë…¸ì¶œë˜ê³  ìˆì–´, ëŒ€ì‘ í•„ìš”(Action required) ì£¼ì œë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.")
    
    # ì½˜í…ì¸  ê¸°íšŒ ì˜ì—­
    if earned_count >= 5 and lg_count == 0:
        summaries.append("í•´ë‹¹ íƒìƒ‰ í‚¤ì›Œë“œëŠ” Earned Media ë¹„ì¤‘ì´ ë†’ì•„, ë¸Œëœë“œ ê°œì… ì—¬ì§€ê°€ í° ì£¼ì œë¡œ íŒë‹¨ë©ë‹ˆë‹¤.")
    
    # LG ì±„ë„ ë…¸ì¶œ í™•ì¸
    if lg_count > 0:
        summaries.append(f"LG ì±„ë„ì´ {lg_count}ê°œ ë…¸ì¶œë˜ì–´ ë¸Œëœë“œ ì¸ì§€ë„ê°€ í™•ì¸ë©ë‹ˆë‹¤.")
    
    # Earned Media ë¹„ì¤‘ì´ ë†’ì€ ê²½ìš°
    earned_ratio = earned_count / total if total > 0 else 0
    if earned_ratio >= 0.5 and earned_count >= 3:
        summaries.append("Earned Media ë¹„ì¤‘ì´ ë†’ì•„, ë¸Œëœë“œ ê°œì… ì—¬ì§€ê°€ í° ì£¼ì œë¡œ íŒë‹¨ë©ë‹ˆë‹¤.")
    
    # ê¸°ë³¸ ìš”ì•½
    if not summaries:
        if competitor_count > 0:
            summaries.append("ê²½ìŸì‚¬ ì½˜í…ì¸ ê°€ ì¼ë¶€ ë…¸ì¶œë˜ê³  ìˆìŠµë‹ˆë‹¤.")
        elif earned_count > 0:
            summaries.append("Earned Media ì½˜í…ì¸ ê°€ ì£¼ë¡œ ë…¸ì¶œë˜ê³  ìˆìŠµë‹ˆë‹¤.")
        else:
            summaries.append("ë‹¤ì–‘í•œ ì±„ë„ì—ì„œ ì½˜í…ì¸ ê°€ ë…¸ì¶œë˜ê³  ìˆìŠµë‹ˆë‹¤.")
    
    return " ".join(summaries)


def render_trend_explorer():
    """êµ¬ê¸€ AI ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ íƒ­ ë Œë”ë§"""
    serp_service = get_serp_service()
    
    # í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ê´€ë¦¬
    if 'aio_display_count' not in st.session_state:
        st.session_state.aio_display_count = 20
    
    try:
        serp_df = serp_service.get_all_serp_data()
        
        if serp_df is None or len(serp_df) == 0:
            st.warning("âš ï¸ êµ¬ê¸€ AI ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ë©´ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            return
        
        # í†µê³„ ìš”ì•½
        filtered_df = serp_df[serp_df['aio_status'].isin(['AVAILABLE', 'NOT_AVAILABLE'])].copy()
        
        if len(filtered_df) == 0:
            st.warning("âš ï¸ í•„í„°ë§ëœ êµ¬ê¸€ AI ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("AVAILABLE ë˜ëŠ” NOT_AVAILABLE ìƒíƒœì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        col1, col2, col3 = st.columns(3)
        
        total_queries = len(filtered_df)
        available_count = len(filtered_df[filtered_df['aio_status'] == 'AVAILABLE'])
        not_available_count = len(filtered_df[filtered_df['aio_status'] == 'NOT_AVAILABLE'])
        
        with col1:
            st.metric("Total Queries", total_queries)
        with col2:
            st.metric("Available", f"{available_count} ({available_count/total_queries*100:.1f}%)" if total_queries > 0 else "0")
        with col3:
            st.metric("Not Available", f"{not_available_count} ({not_available_count/total_queries*100:.1f}%)" if total_queries > 0 else "0")
        
        st.markdown("---")
        
        # í˜„ì¬ í‘œì‹œí•  í•­ëª© ìˆ˜
        display_count = min(st.session_state.aio_display_count, len(filtered_df))
        display_df = filtered_df.head(display_count)
        
        # ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ë²ˆí˜¸ì™€ íƒœê·¸ í¬í•¨)
        for list_idx, (df_idx, row) in enumerate(display_df.iterrows(), start=1):
            # ë²ˆí˜¸ì™€ ì¿¼ë¦¬ ì œëª©
            expander_title = f"{list_idx}. {row['query']}"
            if pd.notna(row.get('snapshot_at')):
                expander_title += f" ({row['snapshot_at']})"
            
            # ìƒíƒœ íƒœê·¸ì™€ í•¨ê»˜ í‘œì‹œ
            col_tag, col_title = st.columns([1, 9])
            with col_tag:
                if row['aio_status'] == 'AVAILABLE':
                    st.markdown(f"<span style='background-color: #dc3545; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.8em;'>Action required</span>", unsafe_allow_html=True)
                else:
                    st.markdown(f"<span style='background-color: #dc3545; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.8em;'>Not Available</span>", unsafe_allow_html=True)
            with col_title:
                with st.expander(expander_title):
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown(f"**ğŸ” Query**: `{row['query']}`")
                    with col2:
                        if pd.notna(row.get('snapshot_at')):
                            st.caption(f"ğŸ“… {row['snapshot_at']}")
                    
                    # AI Overview í…ìŠ¤íŠ¸ ë˜ëŠ” ê²€ìƒ‰ ê²°ê³¼
                    if row['aio_status'] == 'AVAILABLE' and row.get('aio_text'):
                        st.markdown("**ğŸ“„ AI Overview:**")
                        st.info(row['aio_text'])
                    elif row.get('source_table') == 'serp_results':
                        st.markdown("**ğŸ“„ ê²€ìƒ‰ ê²°ê³¼:**")
                        sources = parse_cited_sources(row.get('cited_sources_json'))
                        if sources:
                            st.info(f"ì´ {len(sources)}ê°œì˜ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.")
                    
                    # ì°¸ê³  URL (ì±„ë„ ë¶„ë¥˜)
                    sources = parse_cited_sources(row.get('cited_sources_json'))
                    if sources:
                        st.markdown("**ğŸ”— ì°¸ê³  URL:**")
                        
                        # ì±„ë„ íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
                        lg_sources = [s for s in sources if s.get('channel_type') == 'lg_owned']
                        competitor_sources = [s for s in sources if s.get('channel_type') == 'competitor']
                        earned_sources = [s for s in sources if s.get('channel_type') == 'earned_media']
                        other_sources = [s for s in sources if s.get('channel_type') == 'other']
                        
                        # ì±„ë„ ë¶„í¬ í†µê³„
                        st.markdown("**ğŸ“Œ ì°¸ê³  URL ì±„ë„ ë¶„í¬**")
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("LG Owned", len(lg_sources))
                        with col2:
                            st.metric("Competitor", len(competitor_sources))
                        with col3:
                            st.metric("Earned Media", len(earned_sources))
                        with col4:
                            st.metric("Other", len(other_sources))
                        
                        # ì¹´í…Œê³ ë¦¬ë³„ expanderë¡œ í‘œì‹œ
                        if lg_sources:
                            with st.expander(f"ğŸ  LG Owned ({len(lg_sources)})", expanded=False):
                                for source in lg_sources:
                                    url = source.get('url', '#')
                                    title = source.get('title', source.get('domain', 'N/A'))
                                    snippet = source.get('snippet', '')
                                    # ìƒˆ íƒ­ì—ì„œ ì—´ë¦¬ë„ë¡ HTML ë§í¬ ì‚¬ìš©
                                    st.markdown(f"- **<a href='{url}' target='_blank'>{title}</a>** [LG Owned]", unsafe_allow_html=True)
                                    if snippet:
                                        st.caption(f"  {snippet[:150]}...")
                        
                        if competitor_sources:
                            with st.expander(f"âš”ï¸ Competitor ({len(competitor_sources)})", expanded=False):
                                for source in competitor_sources:
                                    url = source.get('url', '#')
                                    title = source.get('title', source.get('domain', 'N/A'))
                                    snippet = source.get('snippet', '')
                                    st.markdown(f"- **<a href='{url}' target='_blank'>{title}</a>** [Competitor]", unsafe_allow_html=True)
                                    if snippet:
                                        st.caption(f"  {snippet[:150]}...")
                        
                        if earned_sources:
                            with st.expander(f"ğŸ“° Earned Media ({len(earned_sources)})", expanded=False):
                                for source in earned_sources:
                                    url = source.get('url', '#')
                                    title = source.get('title', source.get('domain', 'N/A'))
                                    snippet = source.get('snippet', '')
                                    st.markdown(f"- **<a href='{url}' target='_blank'>{title}</a>** [Earned]", unsafe_allow_html=True)
                                    if snippet:
                                        st.caption(f"  {snippet[:150]}...")
                        
                        if other_sources:
                            with st.expander(f"ğŸ”— Other ({len(other_sources)})", expanded=False):
                                for source in other_sources:
                                    url = source.get('url', '#')
                                    title = source.get('title', source.get('domain', 'N/A'))
                                    snippet = source.get('snippet', '')
                                    st.markdown(f"- **<a href='{url}' target='_blank'>{title}</a>** [Other]", unsafe_allow_html=True)
                                    if snippet:
                                        st.caption(f"  {snippet[:150]}...")
                        
                        # ìš”ì•½ ë¬¸êµ¬ ìë™ ìƒì„±
                        summary_text = generate_channel_summary(
                            len(lg_sources), 
                            len(competitor_sources), 
                            len(earned_sources), 
                            len(other_sources)
                        )
                        if summary_text:
                            st.info(f"ğŸ’¡ **LGì „ì ê´€ì  ìš”ì•½**: {summary_text}")
        
        # More ë²„íŠ¼ (ë” ë§ì€ í•­ëª© í‘œì‹œ)
        st.markdown("---")
        if display_count < len(filtered_df):
            remaining_count = len(filtered_df) - display_count
            if st.button(f"More ({remaining_count}ê°œ ë” ë³´ê¸°)", key="aio_more_button"):
                st.session_state.aio_display_count += 20
                st.rerun()
        else:
            st.info(f"ì „ì²´ {len(filtered_df)}ê°œ í•­ëª©ì„ ëª¨ë‘ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.")
            # ë¦¬ì…‹ ë²„íŠ¼
            if st.button("ì²˜ìŒë¶€í„° ë³´ê¸°", key="aio_reset_button"):
                st.session_state.aio_display_count = 20
                st.rerun()
        
        # CSV ë‹¤ìš´ë¡œë“œ
        st.markdown("---")
        csv = filtered_df.to_csv(index=False)
        st.download_button(
            "SERP ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
            csv,
            "serp_aio_data.csv",
            "text/csv",
            key="download_serp_csv"
        )
        
    except Exception as e:
        st.error(f"Error loading trend explorer data: {e}")
        st.info("Not available")
